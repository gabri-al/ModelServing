{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f83b3f4-16e0-4419-8dd9-4aa8611bcaf9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# AirBnb NY Listing Price Prediction: Register & Serve Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61798dc3-7280-4308-92b9-108ccbf2f809",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Useful Pyfunc and Serving API resources:\n",
    "*  tutorial [link](https://mlflow.org/docs/latest/traditional-ml/serving-multiple-models-with-pyfunc/notebooks/MME_Tutorial.html)\n",
    "*  https://docs.databricks.com/en/machine-learning/model-serving/custom-models.html\n",
    "*  https://docs.databricks.com/en/machine-learning/model-serving/score-custom-model-endpoints.html\n",
    "*  Notebook with example of how to serve and query a custom model https://docs.databricks.com/en/_extras/notebooks/source/machine-learning/deploy-mlflow-pyfunc-model-serving.html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8971ed1-3894-4b8d-b8c9-b2b6e8bc8d11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy\n",
    "import json\n",
    "import os\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigInput, ServedModelInput, ServedModelInputWorkloadSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88879a9f-9c3d-4b49-af55-e57762fb7420",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Define Global Variables\n",
    "catalog_ = os.getenv('CATALOG_NAME')\n",
    "schema_ = os.getenv('SCHEMA_NAME')\n",
    "spark.sql(\"USE CATALOG \"+catalog_)\n",
    "spark.sql(\"USE SCHEMA \"+schema_)\n",
    "\n",
    "SEED_ = 155\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "experiment_name_ = 'Airbnb_NY_Tuning'\n",
    "Train_tbl_Name = 'airbnb_ny_gold_data'\n",
    "xgb_model_name = f\"{catalog_}.{schema_}.airbnb_ny_XGB\"\n",
    "xgb_model_ver = 2\n",
    "rf_model_name = f\"{catalog_}.{schema_}.airbnb_ny_RF\"\n",
    "rf_model_ver = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3dec020-dbe6-496a-a097-f71b0a23d0f5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Register Final Models on UC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c20e18b-c489-46be-83bf-dd70ad278d7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register XGB Model\n",
    "XGB_run_id = '56cf865581eb4b729614b529b88c1a9b'\n",
    "mlflow.register_model(\n",
    "    model_uri=\"runs:/\"+XGB_run_id+\"/model\",\n",
    "    name=xgb_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff5696a7-06be-44ef-81f1-013816fad0b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register RF Model\n",
    "RF_run_id = '0621a09a2af24659b6f4d20d31796980'\n",
    "mlflow.register_model(\n",
    "    model_uri=\"runs:/\"+RF_run_id+\"/model\",\n",
    "    name=rf_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d7b75e5-14af-4927-811e-a54ab9008f34",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Pyfunc: Create a custom class defining the predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25e71a20-8146-4a34-a2a3-0027636181ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class CombiningModels(mlflow.pyfunc.PythonModel):\n",
    "    \n",
    "    # initialize data\n",
    "    def __init__(self, uri_models, weights):\n",
    "        self.uri_models = uri_models # list needed\n",
    "        self.weights = [float(w) for w in weights] # list needed\n",
    "        self.models = []\n",
    "    \n",
    "    # load models from URI\n",
    "    def load_models(self):\n",
    "        for i in range(len(self.uri_models)):\n",
    "            loaded_model_ = mlflow.pyfunc.load_model(self.uri_models[i])\n",
    "            self.models.append(loaded_model_)\n",
    "            #print(\"Model %s loaded!\" % str(i))\n",
    "\n",
    "    # create a custom predict method\n",
    "    def predict(self, context, input_data): # context required as part of the API input\n",
    "        '''input_data received as {'dataframe_split': df.to_dict(orient='split')} and then json.dumps() by the endpoint API but automatically converted to DataFrame'''\n",
    "        final_pred = .0\n",
    "        # custom predict logic\n",
    "        for i in range(len(self.models)):\n",
    "            model_ = self.models[i]\n",
    "            pred_ = model_.predict(input_data)\n",
    "            print(\"Model %s prediction: %.2f\" % (str(i), pred_))\n",
    "            final_pred += pred_ * self.weights[i]\n",
    "        return final_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90908cb7-3bc2-4ae4-ac89-8879100796de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Test the Pyfunc Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a70e5758-7ba0-48c6-a0e5-413b7fbadabb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Copy gold data and split into train and test\n",
    "gold_data = spark.sql(\"SELECT * from \"+Train_tbl_Name)\n",
    "train_df, test_df = gold_data.randomSplit([.85, .15], seed = SEED_)\n",
    "train_df = train_df.toPandas()\n",
    "test_df = test_df.toPandas()\n",
    "\n",
    "display(train_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "072eaad3-01fd-4652-8a2c-b26460932be5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Pick a random datapoint from test set\n",
    "rnd_ = random.randint(0, len(test_df))\n",
    "\n",
    "xTest = test_df.iloc[[rnd_], 1:-2] # Pandas df of 1 row\n",
    "yTest = test_df.loc[rnd_, 'price']\n",
    "\n",
    "print(\"Random point picked:\")\n",
    "display(xTest)\n",
    "\n",
    "#This is how the API input will look like\n",
    "xTest_dict = {'dataframe_split': xTest.to_dict(orient='split')}\n",
    "xTest_api = json.dumps(xTest_dict)\n",
    "print(xTest_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d5bc4ff-fd8c-4c1d-9200-384f77fb7062",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Prepare class parameter and input data\n",
    "weights_ = [0.3, 0.7]\n",
    "uri_models_ = [\n",
    "  f\"models:/{rf_model_name}/{rf_model_ver}\", # Rf model will have weight 0.3\n",
    "  f\"models:/{xgb_model_name}/{xgb_model_ver}\" # XGB model will have weight 0.7\n",
    "]\n",
    "input_data_df = xTest.copy()\n",
    "input_data = xTest_api\n",
    "\n",
    "## Initialize object from class\n",
    "myCustomModel = CombiningModels(uri_models = uri_models_, weights = weights_)\n",
    "myCustomModel.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc89c67d-2918-4989-9479-283fceab6767",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform predictions\n",
    "\n",
    "# Raw prediction from registered models\n",
    "RF_loaded_model_ = mlflow.pyfunc.load_model(uri_models_[0])\n",
    "XGB_loaded_model_ = mlflow.pyfunc.load_model(uri_models_[1])\n",
    "print(\"Original RF model prediction: %.3f\" % RF_loaded_model_.predict(xTest))\n",
    "print(\"Original XGB model prediction: %.3f\" % XGB_loaded_model_.predict(xTest))\n",
    "\n",
    "# Custom predictions from Pyfunc, inferring signature\n",
    "print(\"\\nGenerating prediction via pyfunc:\")\n",
    "customPred = myCustomModel.predict('', xTest)\n",
    "print(\"Final pyfunc custom prediction : %.3f\" % (customPred))\n",
    "signature_ = infer_signature(xTest, customPred)\n",
    "\n",
    "# True price value\n",
    "print(\"\\nTrue price for random point: %.3f\" % yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44b92684-b065-4187-b477-d77083f1039b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Register the pyfunc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc993f2e-6e67-4b2a-a979-c5825ebe3cae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Set up the MLFlow Experiment\n",
    "experiment_path = f'/Users/gabriele.albini@databricks.com/{experiment_name_}'\n",
    "experiment = mlflow.get_experiment_by_name(experiment_path)\n",
    "\n",
    "if experiment is not None:\n",
    "    experiment_id = experiment.experiment_id\n",
    "else:\n",
    "    experiment_id = mlflow.create_experiment(name=experiment_path)\n",
    "\n",
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d29a024d-16ba-42fd-82d9-a6bccc7644b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Log & Register the pyfunc model\n",
    "model_name_ = 'airbnb_ny_pyfunc'\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"Pyfunc_Model\") as run:\n",
    "  mlflow.pyfunc.log_model(\n",
    "    model_name_,\n",
    "    python_model = myCustomModel,\n",
    "    pip_requirements = [\"pandas\", \"numpy\", \"mlflow==2.11.1\", \"scikit-learn==1.4.1.post1\"],\n",
    "    signature = signature_,\n",
    "    registered_model_name = f\"{catalog_}.{schema_}.{model_name_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b653969-67dd-41b9-bc50-9bb6999e8d8d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Serve the pyfunc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b10a45e2-1502-46ca-ba91-f4f646cfcfd5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Define variables for the serving endpoint\n",
    "host = \"https://e2-demo-field-eng.cloud.databricks.com/\"\n",
    "serving_endpoint_name = f\"airbnb_ny_pred\"\n",
    "serving_endpoint_url = f\"{host}/ml/endpoints/{serving_endpoint_name}\"\n",
    "model_path = f\"{catalog_}.{schema_}.{model_name_}\"\n",
    "latest_model_ver = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e8d9a80-48ab-4e5a-895c-5c02dd8451ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Generate endpoint configuration\n",
    "w = WorkspaceClient()\n",
    "endpoint_config = EndpointCoreConfigInput(\n",
    "  name = serving_endpoint_name,\n",
    "  served_models=[\n",
    "    ServedModelInput(\n",
    "      model_name = model_path,\n",
    "      model_version = latest_model_ver,\n",
    "      workload_size = ServedModelInputWorkloadSize.SMALL,\n",
    "      scale_to_zero_enabled = True,\n",
    "      environment_vars = {}\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "\n",
    "# Check if endpoint exists\n",
    "endpoint_exists = False\n",
    "for ep in w.serving_endpoints.list():\n",
    "  if ep.name == serving_endpoint_name:\n",
    "    endpoint_exists = True\n",
    "    break\n",
    "\n",
    "# Create or update endpoint\n",
    "if not endpoint_exists:\n",
    "  print(\"Creating a new serving endpoint: %s\" % serving_endpoint_url)\n",
    "  w.serving_endpoints.create_and_wait(name=serving_endpoint_name, config=endpoint_config)\n",
    "else:\n",
    "  print(\"Updating the serving endpoint:  %s\" % serving_endpoint_url)\n",
    "  w.serving_endpoints.update_config_and_wait(served_models=endpoint_config.served_models, name=serving_endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4145428257173881,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "04_Register_Serve_Models",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
