{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f83b3f4-16e0-4419-8dd9-4aa8611bcaf9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# AirBnb NY Listing Price Prediction: ML Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8971ed1-3894-4b8d-b8c9-b2b6e8bc8d11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6fcbe52-e74b-4fad-bf7e-593e253c3425",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Define Global Variables\n",
    "catalog_ = os.getenv('CATALOG_NAME')\n",
    "schema_ = os.getenv('SCHEMA_NAME')\n",
    "spark.sql(\"USE CATALOG \"+catalog_)\n",
    "spark.sql(\"USE SCHEMA \"+schema_)\n",
    "\n",
    "SEED_ = 334\n",
    "Train_tbl_Name = 'airbnb_ny_gold_data'\n",
    "Target_Var_ = 'price'\n",
    "experiment_name_ = 'Airbnb_NY_Tuning'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b07fbe8-2f88-4633-8efa-c0c4c41969af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Split into Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e6f2c4a-4646-42c7-89e9-998af63af3a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gold_data = spark.sql(\"SELECT * from \"+Train_tbl_Name)\n",
    "train_df, test_df = gold_data.randomSplit([.85, .15], seed = SEED_)\n",
    "train_df = train_df.toPandas()\n",
    "test_df = test_df.toPandas()\n",
    "\n",
    "display(train_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7179847c-0bea-480b-959e-931e131eb31a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert data into np arrays\n",
    "xTrain = train_df.iloc[:, 1:-2].to_numpy()\n",
    "yTrain = train_df.loc[:, Target_Var_].to_numpy()\n",
    "\n",
    "xTest = test_df.iloc[:, 1:-2].to_numpy()\n",
    "yTest = test_df.loc[:, Target_Var_].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51583bdc-1518-4291-b7a7-f66946b8d97d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Extract Model Params from Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1d20614-8616-412d-be01-6c2eb5472cb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Define Base Models\n",
    "rf_base = RandomForestRegressor(random_state = SEED_)\n",
    "xgb_base = GradientBoostingRegressor(random_state = SEED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ded7044-0f41-43bd-b517-01f4dd0dca59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Set up the MLFlow Experiment\n",
    "experiment_path = f'/Users/gabriele.albini@databricks.com/{experiment_name_}'\n",
    "experiment = mlflow.get_experiment_by_name(experiment_path)\n",
    "\n",
    "if experiment is not None:\n",
    "    experiment_id = experiment.experiment_id\n",
    "else:\n",
    "    experiment_id = mlflow.create_experiment(name=experiment_path)\n",
    "\n",
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d91ae01d-4b10-48ac-89e9-20bb46664972",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Define Model details to retrieve\n",
    "models_meta = {\n",
    "  'RandomForestRegressor': {\n",
    "    'model': rf_base, # use set_params() here\n",
    "    'run_ids': [\n",
    "      'c4a291febe8144649fc3b032ed905e06',\n",
    "      '2ca308a2e2a54c6fae2f047a6eb57274',\n",
    "      '92848115fcc941698edddec111dea043'\n",
    "    ],\n",
    "    'params_tuned': { # (param name logged into mlflow, corresponding param name in model) this is needed as tuning was done on spark.ml while here we're using sklearn.ensemble\n",
    "      'featureSubsetStrategy': 'max_features',\n",
    "      'maxDepth': 'max_depth',\n",
    "      'numTrees': 'n_estimators'\n",
    "    },\n",
    "    'eval_metrics': {\n",
    "      'mape': mean_absolute_percentage_error,\n",
    "      'r2': r2_score,\n",
    "      'mse': mean_squared_error\n",
    "    }\n",
    "  },\n",
    "  'GradientBoostingRegressor': {\n",
    "    'model': xgb_base,\n",
    "    'run_ids': [\n",
    "      '9eb02478b0a24684a1d0392e3b4ab809',\n",
    "      '89be137be9c54f8c800a414f22bbc134'\n",
    "    ],\n",
    "    'params_tuned': {\n",
    "      'learning_rate': 'learning_rate',\n",
    "      'max_depth': 'max_depth',\n",
    "      'max_features': 'max_features',\n",
    "      'n_estimators': 'n_estimators'\n",
    "    },\n",
    "    'eval_metrics': {\n",
    "      'mape': mean_absolute_percentage_error,\n",
    "      'r2': r2_score,\n",
    "      'mse': mean_squared_error\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4be66715-31cc-4e37-b86b-1766d4fecc11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Retrieve info from MLflow and Initialize Models\n",
    "def init_models(models_meta_):\n",
    "  models_fin = []\n",
    "  client = mlflow.tracking.MlflowClient()\n",
    "  \n",
    "  for model_type in models_meta_.keys():\n",
    "\n",
    "    ### Get model type details\n",
    "    run_ids_ = models_meta_[model_type]['run_ids']\n",
    "    params_ = models_meta[model_type]['params_tuned']\n",
    "\n",
    "    for r in run_ids_:\n",
    "\n",
    "      ### Initialize a new model\n",
    "      model_ = clone(models_meta_[model_type]['model'])\n",
    "\n",
    "      ### Extract parameters from mlflow run and convert them to the corresponding name and type\n",
    "      run = client.get_run(r)\n",
    "      parameters = run.data.params\n",
    "\n",
    "      parameters_to_set = {}\n",
    "      for param_k, param_v in parameters.items():\n",
    "        if param_k in params_.keys():\n",
    "          param_name = params_[param_k]\n",
    "          param_value = param_v\n",
    "          if param_value.isdigit() and param_name != 'learning_rate':\n",
    "            param_value_fin = int(param_value)\n",
    "          elif param_value == 'onethird':\n",
    "            param_value_fin = float(1/3)\n",
    "          elif param_value == 'None':\n",
    "            param_value_fin = None\n",
    "          elif param_name == 'learning_rate':\n",
    "            param_value_fin = float(param_value)\n",
    "          else:\n",
    "            param_value_fin = param_value\n",
    "          #print(\"Mlflow logged %s with value %s becomes: %s\" % (param_k, param_value, str(param_value_fin)))\n",
    "          parameters_to_set[param_name] = param_value_fin\n",
    "\n",
    "      ### Set identified parameters to the model object\n",
    "      model_.set_params(**parameters_to_set)\n",
    "      models_fin.append(model_)\n",
    "\n",
    "  return models_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ef6547c-5cf0-412e-a813-a7936d018268",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "my_models_ = init_models(models_meta)\n",
    "for m in my_models_:\n",
    "  print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d44746e-fe79-4345-959f-e89e3e3e9b3e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59f580a1-6f48-43ff-96c9-4bb0f0b63c7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"Best Models\") as run:\n",
    "\n",
    "  for j in range(len(my_models_)):\n",
    "    \n",
    "    model_ = my_models_[j]\n",
    "\n",
    "    ## Determine model type\n",
    "    model_type = None\n",
    "    types_ = list(models_meta.keys())\n",
    "    for i in range(len(types_)):\n",
    "      if types_[i] in str(type(model_)):\n",
    "        break\n",
    "    model_type = types_[i] #print(model_type) ## e.g. 'GradientBoostingRegressor'\n",
    "    metrics = models_meta[model_type]['eval_metrics']\n",
    "\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=\"Model-\"+str(j), nested=True) as run:\n",
    "\n",
    "      ## Train & predict\n",
    "      m_trained_ = model_.fit(xTrain, yTrain)\n",
    "      pred_yTrain = m_trained_.predict(xTrain) \n",
    "      pred_yTest = m_trained_.predict(xTest)\n",
    "\n",
    "      ## Log mlflow params\n",
    "      mlflow.log_params(m_trained_.get_params())\n",
    "\n",
    "      ## Calculate and log evaluation metrics\n",
    "      for metric_k, metric_f in metrics.items():\n",
    "        mlflow.log_metric(metric_k+'_train', metric_f(yTrain, pred_yTrain))\n",
    "        mlflow.log_metric(metric_k+'_test', metric_f(yTest, pred_yTest))\n",
    "\n",
    "      ## Log mlflow model\n",
    "      signature_ = mlflow.models.infer_signature(model_input=xTrain[:10], model_output=pred_yTrain[:10])\n",
    "      dataset_train = mlflow.data.load_delta(table_name= str(catalog_+'.'+schema_+'.'+Train_tbl_Name))\n",
    "      mlflow.log_input(dataset_train, context=\"training\") # Allows to build UC Lineage\n",
    "      mlflow.sklearn.log_model(sk_model = m_trained_, artifact_path = \"model\", signature=signature_, input_example=xTest)\n",
    "      #run_id = mlflow.active_run().info.run_id"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4145428257173881,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "03_Model_Selection",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
